{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "#from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, SeparableConv2D, Concatenate, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from numpy import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import glob\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import traning data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(path1,path2):\n",
    "    #pathcut = \"/media/linlab/Seagate Backup Plus Drive/Jess/ECG/picture/20190610_fulldata\"\n",
    "    #print(str.replace(path1,pathcut,\"\"))\n",
    "    #path1 = \"/media/linlab/Seagate Backup Plus Drive/Jess/ECG/picture/20190610_fulldata/New_Normal_tra/V6-Normal-Traditional CWT\"\n",
    "    listing = os.listdir(path1) \n",
    "    num_samples=size(listing)\n",
    "    print (\"Normal data amount:\",num_samples)\n",
    "\n",
    "    #patient\n",
    "    #pathcut = \"/media/linlab/Seagate Backup Plus Drive/Jess/ECG/picture/20190610_fulldata\"\n",
    "    #print(str.replace(path2,pathcut,\"\"))\n",
    "    #path2 = r\"F:\\Jess\\ECG\\20190324_12lead\\12 lead\\有分類的\\Patient_一坨分類\\aVF\" #path\n",
    "    #path2 = \"/media/linlab/Seagate Backup Plus Drive/Jess/ECG/picture/20190610_fulldata/PatientResultsTraditionalCWT/PatientResults/Patient-V6-Traditional CWT\"\n",
    "    listing2 = os.listdir(path2) \n",
    "    num_samples=size(listing2)\n",
    "    print (\"Patient data amount:\",num_samples)\n",
    "    \n",
    "    train_data = []\n",
    "    train_data2 = []\n",
    "\n",
    "    for file in listing :\n",
    "        im = Image.open(path1+\"/\"+file)#Image.open(path1 + '/' + file)\n",
    "        region = (140,50,1085,880)\n",
    "        im = im.crop(region)\n",
    "        im = im.resize((200,200),Image.BILINEAR)\n",
    "        im = np.asarray(im)\n",
    "        im = im/255.\n",
    "        train_data.append(np.transpose(im, (0, 1, 2)))\n",
    "\n",
    "    train_data = np.asarray(train_data)\n",
    "    #print(\"Normal data size:\",train_data.shape)\n",
    "\n",
    "\n",
    "    for file in listing2 :\n",
    "        im = Image.open(path2+\"/\"+file)#Image.open(path1 + '/' + file)\n",
    "        region = (140,50,1085,880)\n",
    "        im = im.crop(region)\n",
    "        im = im.resize((200,200),Image.BILINEAR)\n",
    "        im = np.asarray(im)\n",
    "        im = im/255.\n",
    "        train_data2.append(np.transpose(im, (0, 1, 2)))\n",
    "\n",
    "\n",
    "    secure_random = random.SystemRandom()\n",
    "    secure_random.choice(train_data2)\n",
    "    train_data2 = np.asarray(train_data2)\n",
    "    #print(\"Patient data size:\",train_data2.shape)\n",
    "    #chop the patient data for 255(for balance two group)\n",
    "    \n",
    "    train_data = shuffle(train_data, random_state=6)\n",
    "    train_data_cut= train_data[:train_data2.shape[0],:,:,:]\n",
    "    #print(train_data_cut.shape)\n",
    "    #print(train_data.shape)\n",
    "    #combine two training dataset together\n",
    "    train_data = np.vstack((train_data_cut, train_data2))\n",
    "    #train_data = np.asarray(train_data)\n",
    "    #print(\"training dataset size:\",train_data.shape)\n",
    "    \n",
    "    #print(train_data.shape[0])\n",
    "    train_label=np.ones((train_data.shape[0],1),dtype = int)\n",
    "    half = int(train_data.shape[0]/2)\n",
    "    #print(half)\n",
    "    train_label[0:half]=0  \n",
    "    train_label[half:train_data.shape[0]]=1\n",
    "\n",
    "    #train_label = np_utils.to_categorical(train_label,2)\n",
    "\n",
    "    #print(train_label.shape)\n",
    "    #print(train_label[256:510,:])\n",
    "\n",
    "    #shuffle train data+ label\n",
    "    train_data,train_label = shuffle(train_data,train_label, random_state=2)#random_state使每次結果相同\n",
    "    train_data, test_data, train_label, test_label = train_test_split(train_data, train_label, test_size=0.1, random_state=4)\n",
    "\n",
    "    train_label_one = np_utils.to_categorical(train_label,2)\n",
    "    test_label_one = np_utils.to_categorical(test_label,2)\n",
    "    print(\"train data amount:\", train_data.shape)\n",
    "    print(\"test data amount\", test_data.shape)\n",
    "\n",
    "    return(train_data, test_data,train_label_one, test_label_one,train_label,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
